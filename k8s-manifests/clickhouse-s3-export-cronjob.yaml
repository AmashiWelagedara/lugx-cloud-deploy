apiVersion: batch/v1
kind: CronJob
metadata:
  name: clickhouse-s3-export
spec:
  schedule: "*/10 * * * *"  # runs every 10 minutes
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: clickhouse-exporter
            image: clickhouse/clickhouse-server:latest
            command:
            - /bin/bash
            - -c
            - |
              apt update && apt install -y python3-pip && pip3 install awscli && \
              clickhouse-client --host localhost --user default --password mysecret --query "
                SELECT event_type, page_url, user_agent, timestamp
                FROM analytics.page_events
                ORDER BY timestamp DESC
                FORMAT CSVWithNames
              " > page_events.csv && \
              export AWS_ACCESS_KEY_ID=AKIA3PDRSOVYHBDRGAOC && \
              export AWS_SECRET_ACCESS_KEY=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 && \
              aws s3 cp page_events.csv s3://lugx-analytics-bucket/page_events.csv
          restartPolicy: OnFailure
